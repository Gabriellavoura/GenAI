# Material de apoio - GenAI

Este material tem como objetivo apresentar fontes de estudo e referÃªncias multidisciplinares para uma imersÃ£o introdutÃ³ria no campo da InteligÃªncia Artificial, com foco especial em GenAI (InteligÃªncia Artificial Generativa).


## GlossÃ¡rio 2025-06

Este glossÃ¡rio apresenta alguns dos termos, nÃ£o todos, porÃ©m serve como ponto de partida para contextualizaÃ§Ã£o dentre as tecnicas existentes.

A estrutura descrita a seguir descreve em detalhes a taxonomia descrita no diagrama de venn da figura abaixo.

<p align="center">
  <img src="img/VennDiagramIA.png" alt="Diagrama de Veen representando relaÃ§Ã£o das tecnicas e subclassificaÃ§Ãµes de IA" width="400"/>
</p>


> Escolha um tÃ³pico de interesse, estude os conceitos e tecnologias.

```shell
Artificial Intelligence
â”” Machine Learning
    â”œâ”€â”€ Supervised Learning
    â”‚    â”œâ”€â”€ Linear & Logistic Regression
    â”‚    â”œâ”€â”€ Decision Trees / XGBoost
    â”‚    â””â”€â”€ K-Nearest Neighbors (KNN)
    â”œâ”€â”€ Unsupervised Learning
    â”‚    â”œâ”€â”€ Clustering (e.g., K-Means, DBSCAN)
    â”‚    â””â”€â”€ Dimensionality Reduction (PCA, UMAP)
    â”œâ”€â”€ Reinforcement Learning
    â”‚    â”œâ”€â”€ Q-Learning
    â”‚    â””â”€â”€ Deep Reinforcement Learning (DQN, PPO)
    â””â”€â”€ Deep Learning
         â”œâ”€â”€ Feedforward Neural Networks (FNN)
         â”œâ”€â”€ Convolutional Neural Networks (CNN)
         â”œâ”€â”€ Recurrent Neural Networks (RNN, LSTM, GRU)
         â”œâ”€â”€ Graph Neural Networks (GNNs)
         â”‚   â”œâ”€â”€ Graph2Text
         â”‚   â””â”€â”€ Bioinformatics (e.g., molecule generation)
         â”œâ”€â”€ Autoencoders (VAE, Denoising)
         â”œâ”€â”€ Transformers
         â”‚    â”œâ”€â”€ Encoder-only (BERT, DeBERTa)
         â”‚    â”œâ”€â”€ Decoder-only (GPT family)
         â”‚    â””â”€â”€ Encoder-Decoder (T5, UL2)
         â”œâ”€â”€ Generative Adversarial Networks (GANs)
         â”œâ”€â”€ Diffusion Models (modern GAN alternative)
         â””â”€â”€ Generative AI (GenAI)
             â”œâ”€â”€ Large Language Models (LLMs) - Foundation Models
             â”‚    â”œâ”€â”€ GPT-4, GPT-4o (OpenAI)
             â”‚    â”œâ”€â”€ Claude 3, 4 (Anthropic)
             â”‚    â”œâ”€â”€ Gemini 1.5, 2.5 (Google DeepMind)
             â”‚    â”œâ”€â”€ LLaMA 3 (Meta)
             â”‚    â”œâ”€â”€ Mistral / Mixtral
             â”‚    â”œâ”€â”€ Orca / Phi (Microsoft Research)
             â”‚    â”œâ”€â”€ Technologies
             â”‚	  â”‚    â”œâ”€â”€ Prompt Engineering & Controlled Generation
             â”‚    â”‚    â”œâ”€â”€ Few-shot / Zero-shot
             â”‚    â”‚    â”œâ”€â”€ Chain-of-Thought (CoT)
             â”‚    â”‚    â”œâ”€â”€ ReAct (Reason + Act)
             â”‚    â”‚    â”œâ”€â”€ Function Calling / Toolformer
             â”‚    â”‚    â”œâ”€â”€ Tree of Thoughts / Graph of Thoughts
             â”‚    â”‚    â”œâ”€â”€ Structured Prompts (JSON, Markdown)
             â”‚    â”‚    â””â”€â”€ Agents (AutoGPT, CrewAI, OpenDevin)
             â”‚    â”œâ”€â”€ Fine-tuning & Adaptation
             â”‚    â”‚    â”œâ”€â”€ LoRA / QLoRA
             â”‚    â”‚    â”œâ”€â”€ SFT / Instruction Tuning
             â”‚    â”‚    â”œâ”€â”€ Delta tuning / Adapter tuning
             â”‚    â”‚    â””â”€â”€ DPO (Direct Preference Optimization)
             â”‚    â”œâ”€â”€ Efficiency & Compression
             â”‚    â”‚    â”œâ”€â”€ Quantization (INT4, GPTQ, AWQ)
             â”‚    â”‚    â”œâ”€â”€ Model Distillation (e.g., DistilBERT)
             â”‚    â”‚    â”œâ”€â”€ Mixture of Experts (MoE)
             â”‚    â”‚    â””â”€â”€ Sparse Models / Weight Sharing
             â”‚    â”œâ”€â”€ Long Context & Memory
             â”‚    â”‚    â”œâ”€â”€ Long-context models (Claude 3.5, Gemini 1.5)
             â”‚    â”‚    â”œâ”€â”€ FlashAttention / Mamba / RWKV
             â”‚    â”‚    â”œâ”€â”€ Memory-augmented LLMs
             â”‚    â”‚    â””â”€â”€ Retrieval-based episodic memory
             â”‚    â””â”€â”€ Alignment & Safety
             â”‚         â”œâ”€â”€ RLHF / DPO / Constitutional AI
             â”‚         â””â”€â”€ Guardrails, Jailbreak Prevention
             â”œâ”€â”€ Vision-Language Models (VLMs)
             â”‚    â”œâ”€â”€ CLIP / SigLIP
             â”‚    â”œâ”€â”€ GPT-4V (Vision)
             â”‚    â”œâ”€â”€ Gemini Vision
             â”‚    â”œâ”€â”€ Kosmos-2
             â”‚    â””â”€â”€ MM1 / Flamingo
             â”œâ”€â”€ Multimodal Models
             â”‚    â”œâ”€â”€ GPT-4o (text + vision + audio)
             â”‚    â”œâ”€â”€ Gemini 1.5 Pro
             â”‚    â”œâ”€â”€ Fuyu, MM-ReAct
             â”‚    â”œâ”€â”€ SeamlessM4T (Meta, speech translation)
             â”‚    â””â”€â”€ VILA, IDEFICS
             â”œâ”€â”€ Audio, Speech & Music Generation
             â”‚    â”œâ”€â”€ ElevenLabs (speech synthesis)
             â”‚    â”œâ”€â”€ Suno AI (music)
             â”‚    â”œâ”€â”€ Bark, AudioCraft
             â”‚    â””â”€â”€ MusicGen 2
             â”œâ”€â”€ Code Generation
             â”‚    â”œâ”€â”€ Copilot (GitHub + GPT-4)
             â”‚    â”œâ”€â”€ Code Llama 70B / DeepSeek-Coder
             â”‚    â”œâ”€â”€ Claude Instant (code use cases)
             â”‚    â”œâ”€â”€ StarCoder2 / ReplitCode
             â”‚    â””â”€â”€ Codeium / Tabby
             â”œâ”€â”€ Retrieval-Augmented Generation (RAG)
             â”‚    â”œâ”€â”€ Embedding Models
             â”‚    â”‚   â”œâ”€â”€ OpenAI (`text-embedding-3`)
             â”‚    â”‚   â”œâ”€â”€ Cohere Embed v3
             â”‚    â”‚   â””â”€â”€ BGE / E5 / Jina
             â”‚    â”œâ”€â”€ Vector Stores
             â”‚    â”‚   â”œâ”€â”€ FAISS
             â”‚    â”‚   â”œâ”€â”€ Chroma / LanceDB
             â”‚    â”‚   â””â”€â”€ Weaviate / Qdrant / Milvus
             â”‚    â”œâ”€â”€ Frameworks
             â”‚    â”‚   â”œâ”€â”€ LangChain
             â”‚    â”‚   â”œâ”€â”€ LlamaIndex
             â”‚    â”‚   â”œâ”€â”€ Haystack
             â”‚    â”‚   â””â”€â”€ Embedchain, Flowise
             â”‚    â””â”€â”€ RAG Variants
             â”‚        â”œâ”€â”€ RAG-Fusion
             â”‚        â”œâ”€â”€ Context Compression
             â”‚        â””â”€â”€ Agentic RAG / Hierarchical RAG
             â”œâ”€â”€ Agents & Orchestration
             â”‚    â”œâ”€â”€ AutoGPT / BabyAGI
             â”‚    â”œâ”€â”€ LangGraph
             â”‚    â”œâ”€â”€ CrewAI
             â”‚    â”œâ”€â”€ OpenDevin
             â”‚    â””â”€â”€ ReAct / Plan-and-Execute patterns
             â”œâ”€â”€ Evaluation, Safety & Auditing
             â”‚    â”œâ”€â”€ LLM Benchmarks (MMLU, ARC, BigBench, HELM)
             â”‚    â”œâ”€â”€ Guardrails & Safety layers
             â”‚    â”œâ”€â”€ Red-teaming & Jailbreak detection
             â”‚    â””â”€â”€ Synthetic Data / Data Provenance
             â””â”€â”€ Graph-enhanced GenAI
                  â”œâ”€â”€ Knowledge Graphs (KGs)
                  â”‚   â”œâ”€â”€ KG-RAG
                  â”‚   â””â”€â”€ Ontologies (e.g., Wikidata)
                  â”œâ”€â”€ Scene Graphs (Multimodal reasoning)
                  â””â”€â”€ Neuro-Symbolic Integration
```

###  ğŸ“– **Livros**
* **[Deep Learning](https://www.deeplearningbook.org/) - Ian Goodfellow, Yoshua Bengio e Aaron Courville**
*  **Artificial Intelligence: A Modern Approach" por Stuart Russell e Peter Norvig**
### ğŸ“º**Cursos Online**
* **[CS50 - Introduction to Artificial Intelligence with Python](https://pll.harvard.edu/course/cs50s-introduction-artificial-intelligence-python) (Harvard - David Malan)**
* **[AI for Everyone](https://www.coursera.org/learn/ai-for-everyone)" (Coursera - Andrew Ng)**
* **[Machine Learning](https://www.coursera.org/specializations/machine-learning-introduction)" (Coursera - Andrew Ng)**
* **[Deep Learning Specialization](https://www.coursera.org/specializations/deep-learning)" (Coursera - deeplearning.ai)**
* **[Course.fast.ai](https://course.fast.ai/)**
* **[Introduction to Large Language Models](https://www.cloudskillsboost.google/course_templates/539) - Google Cloud**
### ğŸ“„**Artigos (LLM)**
* **[Attention Is All You Need](https://www.youtube.com/watch?v=wjZofJX0v4M) (Vaswani et al., 2017)**
* **[BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding (Devlin et al., 2018)](https://arxiv.org/abs/1810.04805)**
* **[GPT-3: Language Models are Few-Shot Learners (Brown et al., 2020)](https://arxiv.org/abs/2005.14165)**
* **[Papers with code](https://paperswithcode.com/)**
### ğŸ“š**MISC**
* **[Open AI Cookbook]( https://github.com/openai/openai-cookbook)**
* **[Blog da Hugging Face](https://huggingface.co/blog)**
* **[A Very Gentle Introduction to Large Language Models without the Hype](https://mark-riedl.medium.com/a-very-gentle-introduction-to-large-language-models-without-the-hype-5f67941fa59e)** 
- **[The Illustrated Transformer](http://jalammar.github.io/illustrated-transformer/)** 
- **[What Is ChatGPT Doingâ€¦ and Why Does It Work?](https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/)** 
- **[What is RAG?](https://blogs.nvidia.com/blog/what-is-retrieval-augmented-generation/)**
- [RAG vs Fine-tuning](https://towardsdatascience.com/rag-vs-finetuning-which-is-the-best-tool-to-boost-your-llm-application-94654b1eaba7) - ComparaÃ§Ã£o de abordagens
- **[Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks â€“ Artigo da Meta AI](https://arxiv.org/abs/2005.11401)**
- **[RAG Explained in 5 Minutes](https://www.youtube.com/watch?v=T-D1OfcDW1M)**
- [LangChain](https://python.langchain.com/docs/tutorials/rag/) - Biblioteca Python para construir sistemas RAG. 
### ğŸ¥ **Canais:**
* **[Let's build GPT: from scratch, in code, spelled out.](https://www.youtube.com/watch?v=kCc8FmEb1nY)- Andrej Karpathy (1h)**
* **[Large Language Models explained briefly](https://www.youtube.com/watch?v=LPZh9BOjkQs) - 3blue1brown (10min)**
* **[Neural networks](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi) - 3blue1brown (10min)****
* **[Large Language Models Explained](https://www.youtube.com/watch?v=5sLYAQS9sWQ) - Andrej Karpathy (1h)**
- **[Intro to Large Language Models](https://www.youtube.com/watch?v=zjkBMFhNj_g) - Andrej Karpathy (1h)**
- **[How ChatGPT Works Technically](https://www.youtube.com/watch?v=bSvTVREwSNw) - ByteByteGo(30min)**
- **[sentdex](https://www.youtube.com/user/sentdex)**
- **[Sebastian Raschka](https://www.youtube.com/@SebastianRaschka)**
- **[Jeremy Howard - course.fast.ai](https://www.youtube.com/@howardjeremyp)**
- **[MIT OpenCourseWare](https://www.youtube.com/@mitocw)**
- **[Stanford Online](https://www.youtube.com/@stanfordonline)**
- **[Stanford Online](https://www.youtube.com/@stanfordonline)**


---
## **ğŸ› ï¸ Tutoriais PrÃ¡ticos**

- **[Build a RAG App with Python](https://python.langchain.com/docs/tutorials/rag)**
- **[llama.cpp](https://github.com/ggml-org/llama.cpp)**
- **[Ollama](https://ollama.com/)**
- **[Running Ollama on Docker: A Quick Guide](https://dev.to/gabriellavoura/running-ollama-on-docker-a-quick-guide-475l)**
- **[RAG 101](https://txt.cohere.com/rag-101/ )**
- **[Building RAG from Scratch](https://www.youtube.com/watch?v=BrsocJb-fAo)** - Coding with Lewis (45min)

### **ğŸ”§ Ferramentas e Plataformas**
* **Desenvolvimento**
	- **[Hugging Face](https://huggingface.co/)** - Hub de modelos e datasets
	- **[LangChain](https://python.langchain.com/)** - Framework para aplicaÃ§Ãµes LLM
	- **[LlamaIndex](https://www.llamaindex.ai/)** - Framework para RAG
	- **[chainlit](https://docs.chainlit.io/get-started/overview) - Framework para interfaces**
	- **[Streamlit](https://streamlit.io/) - Framework para interfaces**
	- **[Gradio](https://www.gradio.app/) - Deploy de notebooks como aplicaÃ§Ãµes**
	- **[Google Colab](https://colab.google/) - Notebook python com suporte a GPU/TPUs**
	- **[Free LLM APis Resource](https://github.com/cheahjs/free-llm-api-resources)**
* **Bancos Vetoriais**
	- **[Chroma](https://www.trychroma.com/)** - Open-source vector store
	- **[Weaviate](https://weaviate.io/)** - Vector database com GraphQL
	- **[FAISS](https://faiss.ai/)** - Facebook AI Similarity Search
* **AvaliaÃ§Ã£o**
	- **[RAGAS](https://docs.ragas.io/)** - Framework de avaliaÃ§Ã£o para RAG
	- **[TruLens](https://www.trulens.org/)** - AvaliaÃ§Ã£o de aplicaÃ§Ãµes LLM

---

## ğŸ§ª Desafio TÃ©cnico: Construa seu Mini Chat-GPT local com conhecimento personalizado

Neste desafio, vocÃª deverÃ¡ construir um assistente conversacional local e leve usando modelos pequenos de 3B a 7B parÃ¢metros como LLaMA 3.x, DeepSeek, Qwen, Mistral ou Gemma, rodando via Ollama ou llama.cpp, utilizando a linguagem de programaÃ§Ã£o python e o framework langchain.
A aplicaÃ§Ã£o deve ser baseada na tÃ©cnica de RAG (Retrieval-Augmented Generation), onde o LLM responde perguntas a partir de documentos fornecidos por vocÃª.

Ao concluir este desafio vocÃª aprenderÃ¡ a:
* Usar um modelo local (ollama/llama.cpp com deepseek-r1, ou llama3.2/3.1, Qwen3)
* Manipular o framework langchain.
* Montar um sistema de busca semÃ¢ntica de documentos (ChromaDB)
* Desenvolver um frontend de chat (com Chainlit/streamlit)
* Conceitos gerais de LLMs e RAG.

### Dicas:
* Utilize `prompt templates` para personalizar as interaÃ§Ãµes e dividir atividades complexas.
* Armazenar as respostas (caching)  para evitar reprocessar informaÃ§Ãµes [redis](https://redis.io/).

### Follow-up: 

ApÃ³s concluir o desafio principal, implemente algumas das aplicaÃ§Ãµes abaixo.

| Tarefa                | Objetivo                                                                          |
| --------------------- | --------------------------------------------------------------------------------- |
| ğŸ“‘ SumarizaÃ§Ã£o        | Gerar resumo automÃ¡tico de PDF ou artigos cientÃ­ficos                             |
| ğŸ“„ ExtraÃ§Ã£o de dados  | Pegar datas, nomes, cÃ³digos de um documento estruturado                           |
| âœ… ClassificaÃ§Ã£o       | Separar textos entre positivos/negativos (sentimento, tema)                       |
| ğŸ¤– Assistente offline | Criar um bot de ajuda local para um domÃ­nio especÃ­fico                            |
| ğŸ§  Fine-tuning leve   | Usar QLoRA com dados prÃ³prios para melhorar respostas                             |
| ğŸ“š RAG Multifonte     | Buscar respostas em vÃ¡rios conjuntos (artigos + manuais)                          |
| ğŸ” Busca semÃ¢ntica    | Procurar termos "similares" sem depender de palavras-chave (distÃ¢ncias vetoriais) |

> **Keywords**: RAG, LLM, Prompt Template, langchain, vectorial database, chromadb, python
