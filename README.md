# Material de apoio - GenAI

Este material tem como objetivo apresentar fontes de estudo e refer√™ncias multidisciplinares para uma imers√£o introdut√≥ria no campo da Intelig√™ncia Artificial, com foco em GenAI (Intelig√™ncia Artificial Generativa).

> :construction: 2025-06-25 ‚Äî WIP (Work in Progress)


## Mapa conceitual (2025-06)

Este gloss√°rio apresenta alguns dos termos, n√£o todos, por√©m serve como ponto de partida para contextualiza√ß√£o dentre as tecnicas existentes.

A estrutura descrita a seguir descreve em detalhes a taxonomia descrita no diagrama de venn da figura abaixo.

<p align="center">
  <img src="img/VennDiagramIA.png" alt="Diagrama de Veen representando rela√ß√£o das tecnicas e subclassifica√ß√µes de IA" width="400"/>
</p>


> Escolha um t√≥pico de interesse, estude os conceitos e tecnologias.

```shell
Artificial Intelligence
‚îî Machine Learning
    ‚îú‚îÄ‚îÄ Supervised Learning
    ‚îÇ    ‚îú‚îÄ‚îÄ Linear & Logistic Regression
    ‚îÇ    ‚îú‚îÄ‚îÄ Decision Trees / XGBoost
    ‚îÇ    ‚îî‚îÄ‚îÄ K-Nearest Neighbors (KNN)
    ‚îú‚îÄ‚îÄ Unsupervised Learning
    ‚îÇ    ‚îú‚îÄ‚îÄ Clustering (e.g., K-Means, DBSCAN)
    ‚îÇ    ‚îî‚îÄ‚îÄ Dimensionality Reduction (PCA, UMAP)
    ‚îú‚îÄ‚îÄ Reinforcement Learning
    ‚îÇ    ‚îú‚îÄ‚îÄ Q-Learning
    ‚îÇ    ‚îî‚îÄ‚îÄ Deep Reinforcement Learning (DQN, PPO)
    ‚îî‚îÄ‚îÄ Deep Learning
         ‚îú‚îÄ‚îÄ Feedforward Neural Networks (FNN)
         ‚îú‚îÄ‚îÄ Convolutional Neural Networks (CNN)
         ‚îú‚îÄ‚îÄ Recurrent Neural Networks (RNN, LSTM, GRU)
         ‚îú‚îÄ‚îÄ Graph Neural Networks (GNNs)
         ‚îÇ   ‚îú‚îÄ‚îÄ Graph2Text
         ‚îÇ   ‚îî‚îÄ‚îÄ Bioinformatics (e.g., molecule generation)
         ‚îú‚îÄ‚îÄ Autoencoders (VAE, Denoising)
         ‚îú‚îÄ‚îÄ Transformers
         ‚îÇ    ‚îú‚îÄ‚îÄ Encoder-only (BERT, DeBERTa)
         ‚îÇ    ‚îú‚îÄ‚îÄ Decoder-only (GPT family)
         ‚îÇ    ‚îî‚îÄ‚îÄ Encoder-Decoder (T5, UL2)
         ‚îú‚îÄ‚îÄ Generative Adversarial Networks (GANs)
         ‚îú‚îÄ‚îÄ Diffusion Models (modern GAN alternative)
         ‚îî‚îÄ‚îÄ Generative AI (GenAI)
             ‚îú‚îÄ‚îÄ Large Language Models (LLMs) - Foundation Models
             ‚îÇ    ‚îú‚îÄ‚îÄ GPT-4, GPT-4o (OpenAI)
             ‚îÇ    ‚îú‚îÄ‚îÄ Claude 3, 4 (Anthropic)
             ‚îÇ    ‚îú‚îÄ‚îÄ Gemini 1.5, 2.5 (Google DeepMind)
             ‚îÇ    ‚îú‚îÄ‚îÄ LLaMA 3 (Meta)
             ‚îÇ    ‚îú‚îÄ‚îÄ Mistral / Mixtral
             ‚îÇ    ‚îú‚îÄ‚îÄ Orca / Phi (Microsoft Research)
             ‚îÇ    ‚îú‚îÄ‚îÄ Technologies
             ‚îÇ	  ‚îÇ    ‚îú‚îÄ‚îÄ Prompt Engineering & Controlled Generation
             ‚îÇ    ‚îÇ    ‚îú‚îÄ‚îÄ Few-shot / Zero-shot
             ‚îÇ    ‚îÇ    ‚îú‚îÄ‚îÄ Chain-of-Thought (CoT)
             ‚îÇ    ‚îÇ    ‚îú‚îÄ‚îÄ ReAct (Reason + Act)
             ‚îÇ    ‚îÇ    ‚îú‚îÄ‚îÄ Function Calling / Toolformer
             ‚îÇ    ‚îÇ    ‚îú‚îÄ‚îÄ Tree of Thoughts / Graph of Thoughts
             ‚îÇ    ‚îÇ    ‚îú‚îÄ‚îÄ Structured Prompts (JSON, Markdown)
             ‚îÇ    ‚îÇ    ‚îî‚îÄ‚îÄ Agents (AutoGPT, CrewAI, OpenDevin)
             ‚îÇ    ‚îú‚îÄ‚îÄ Fine-tuning & Adaptation
             ‚îÇ    ‚îÇ    ‚îú‚îÄ‚îÄ LoRA / QLoRA
             ‚îÇ    ‚îÇ    ‚îú‚îÄ‚îÄ SFT / Instruction Tuning
             ‚îÇ    ‚îÇ    ‚îú‚îÄ‚îÄ Delta tuning / Adapter tuning
             ‚îÇ    ‚îÇ    ‚îî‚îÄ‚îÄ DPO (Direct Preference Optimization)
             ‚îÇ    ‚îú‚îÄ‚îÄ Efficiency & Compression
             ‚îÇ    ‚îÇ    ‚îú‚îÄ‚îÄ Quantization (INT4, GPTQ, AWQ)
             ‚îÇ    ‚îÇ    ‚îú‚îÄ‚îÄ Model Distillation (e.g., DistilBERT)
             ‚îÇ    ‚îÇ    ‚îú‚îÄ‚îÄ Mixture of Experts (MoE)
             ‚îÇ    ‚îÇ    ‚îî‚îÄ‚îÄ Sparse Models / Weight Sharing
             ‚îÇ    ‚îú‚îÄ‚îÄ Long Context & Memory
             ‚îÇ    ‚îÇ    ‚îú‚îÄ‚îÄ Long-context models (Claude 3.5, Gemini 1.5)
             ‚îÇ    ‚îÇ    ‚îú‚îÄ‚îÄ FlashAttention / Mamba / RWKV
             ‚îÇ    ‚îÇ    ‚îú‚îÄ‚îÄ Memory-augmented LLMs
             ‚îÇ    ‚îÇ    ‚îî‚îÄ‚îÄ Retrieval-based episodic memory
             ‚îÇ    ‚îî‚îÄ‚îÄ Alignment & Safety
             ‚îÇ         ‚îú‚îÄ‚îÄ RLHF / DPO / Constitutional AI
             ‚îÇ         ‚îî‚îÄ‚îÄ Guardrails, Jailbreak Prevention
             ‚îú‚îÄ‚îÄ Vision-Language Models (VLMs)
             ‚îÇ    ‚îú‚îÄ‚îÄ CLIP / SigLIP
             ‚îÇ    ‚îú‚îÄ‚îÄ GPT-4V (Vision)
             ‚îÇ    ‚îú‚îÄ‚îÄ Gemini Vision
             ‚îÇ    ‚îú‚îÄ‚îÄ Kosmos-2
             ‚îÇ    ‚îî‚îÄ‚îÄ MM1 / Flamingo
             ‚îú‚îÄ‚îÄ Multimodal Models
             ‚îÇ    ‚îú‚îÄ‚îÄ GPT-4o (text + vision + audio)
             ‚îÇ    ‚îú‚îÄ‚îÄ Gemini 1.5 Pro
             ‚îÇ    ‚îú‚îÄ‚îÄ Fuyu, MM-ReAct
             ‚îÇ    ‚îú‚îÄ‚îÄ SeamlessM4T (Meta, speech translation)
             ‚îÇ    ‚îî‚îÄ‚îÄ VILA, IDEFICS
             ‚îú‚îÄ‚îÄ Audio, Speech & Music Generation
             ‚îÇ    ‚îú‚îÄ‚îÄ ElevenLabs (speech synthesis)
             ‚îÇ    ‚îú‚îÄ‚îÄ Suno AI (music)
             ‚îÇ    ‚îú‚îÄ‚îÄ Bark, AudioCraft
             ‚îÇ    ‚îî‚îÄ‚îÄ MusicGen 2
             ‚îú‚îÄ‚îÄ Code Generation
             ‚îÇ    ‚îú‚îÄ‚îÄ Copilot (GitHub + GPT-4)
             ‚îÇ    ‚îú‚îÄ‚îÄ Code Llama 70B / DeepSeek-Coder
             ‚îÇ    ‚îú‚îÄ‚îÄ Claude Instant (code use cases)
             ‚îÇ    ‚îú‚îÄ‚îÄ StarCoder2 / ReplitCode
             ‚îÇ    ‚îî‚îÄ‚îÄ Codeium / Tabby
             ‚îú‚îÄ‚îÄ Retrieval-Augmented Generation (RAG)
             ‚îÇ    ‚îú‚îÄ‚îÄ Embedding Models
             ‚îÇ    ‚îÇ   ‚îú‚îÄ‚îÄ OpenAI (`text-embedding-3`)
             ‚îÇ    ‚îÇ   ‚îú‚îÄ‚îÄ Cohere Embed v3
             ‚îÇ    ‚îÇ   ‚îî‚îÄ‚îÄ BGE / E5 / Jina
             ‚îÇ    ‚îú‚îÄ‚îÄ Vector Stores
             ‚îÇ    ‚îÇ   ‚îú‚îÄ‚îÄ FAISS
             ‚îÇ    ‚îÇ   ‚îú‚îÄ‚îÄ Chroma / LanceDB
             ‚îÇ    ‚îÇ   ‚îî‚îÄ‚îÄ Weaviate / Qdrant / Milvus
             ‚îÇ    ‚îú‚îÄ‚îÄ Frameworks
             ‚îÇ    ‚îÇ   ‚îú‚îÄ‚îÄ LangChain
             ‚îÇ    ‚îÇ   ‚îú‚îÄ‚îÄ LlamaIndex
             ‚îÇ    ‚îÇ   ‚îú‚îÄ‚îÄ Haystack
             ‚îÇ    ‚îÇ   ‚îî‚îÄ‚îÄ Embedchain, Flowise
             ‚îÇ    ‚îî‚îÄ‚îÄ RAG Variants
             ‚îÇ        ‚îú‚îÄ‚îÄ RAG-Fusion
             ‚îÇ        ‚îú‚îÄ‚îÄ Context Compression
             ‚îÇ        ‚îî‚îÄ‚îÄ Agentic RAG / Hierarchical RAG
             ‚îú‚îÄ‚îÄ Agents & Orchestration
             ‚îÇ    ‚îú‚îÄ‚îÄ AutoGPT / BabyAGI
             ‚îÇ    ‚îú‚îÄ‚îÄ LangChain / LangGraph
             ‚îÇ    ‚îú‚îÄ‚îÄ CrewAI
             ‚îÇ    ‚îú‚îÄ‚îÄ OpenDevin
             ‚îÇ    ‚îî‚îÄ‚îÄ ReAct / Plan-and-Execute patterns
             ‚îú‚îÄ‚îÄ Evaluation, Safety & Auditing
             ‚îÇ    ‚îú‚îÄ‚îÄ LLM Benchmarks (MMLU, ARC, BigBench, HELM)
             ‚îÇ    ‚îú‚îÄ‚îÄ Guardrails & Safety layers
             ‚îÇ    ‚îú‚îÄ‚îÄ Red-teaming & Jailbreak detection
             ‚îÇ    ‚îî‚îÄ‚îÄ Synthetic Data / Data Provenance
             ‚îî‚îÄ‚îÄ Graph-enhanced GenAI
                  ‚îú‚îÄ‚îÄ Knowledge Graphs (KGs)
                  ‚îÇ   ‚îú‚îÄ‚îÄ KG-RAG
                  ‚îÇ   ‚îî‚îÄ‚îÄ Ontologies (e.g., Wikidata)
                  ‚îú‚îÄ‚îÄ Scene Graphs (Multimodal reasoning)
                  ‚îî‚îÄ‚îÄ Neuro-Symbolic Integration
```

###  üìñ **Livros**
* **[Deep Learning](https://www.deeplearningbook.org/) - Ian Goodfellow, Yoshua Bengio e Aaron Courville**
*  **Artificial Intelligence: A Modern Approach" por Stuart Russell e Peter Norvig**
### üì∫**Cursos Online**
* **[CS50 - Introduction to Artificial Intelligence with Python](https://pll.harvard.edu/course/cs50s-introduction-artificial-intelligence-python) (Harvard - David Malan)**
* **[AI for Everyone](https://www.coursera.org/learn/ai-for-everyone)" (Coursera - Andrew Ng)**
* **[Machine Learning](https://www.coursera.org/specializations/machine-learning-introduction)" (Coursera - Andrew Ng)**
* **[Deep Learning Specialization](https://www.coursera.org/specializations/deep-learning)" (Coursera - deeplearning.ai)**
* **[Course.fast.ai](https://course.fast.ai/)**
* **[Introduction to Large Language Models](https://www.cloudskillsboost.google/course_templates/539) - Google Cloud**
### üìÑ**Artigos (LLM)**
* **[Attention Is All You Need](https://www.youtube.com/watch?v=wjZofJX0v4M) (Vaswani et al., 2017)**
* **[BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding (Devlin et al., 2018)](https://arxiv.org/abs/1810.04805)**
* **[GPT-3: Language Models are Few-Shot Learners (Brown et al., 2020)](https://arxiv.org/abs/2005.14165)**
* **[Papers with code](https://paperswithcode.com/)**
### üìö**MISC**
* **[Open AI Cookbook]( https://github.com/openai/openai-cookbook)**
* **[Blog da Hugging Face](https://huggingface.co/blog)**
* **[A Very Gentle Introduction to Large Language Models without the Hype](https://mark-riedl.medium.com/a-very-gentle-introduction-to-large-language-models-without-the-hype-5f67941fa59e)** 
- **[The Illustrated Transformer](http://jalammar.github.io/illustrated-transformer/)** 
- **[What Is ChatGPT Doing‚Ä¶ and Why Does It Work?](https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/)** 
- **[What is RAG?](https://blogs.nvidia.com/blog/what-is-retrieval-augmented-generation/)**
- [RAG vs Fine-tuning](https://towardsdatascience.com/rag-vs-finetuning-which-is-the-best-tool-to-boost-your-llm-application-94654b1eaba7) - Compara√ß√£o de abordagens
- **[Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks ‚Äì Artigo da Meta AI](https://arxiv.org/abs/2005.11401)**
- **[RAG Explained in 5 Minutes](https://www.youtube.com/watch?v=T-D1OfcDW1M)**
- [LangChain](https://python.langchain.com/docs/tutorials/rag/) - Biblioteca Python para construir sistemas RAG. 
### üé• **Canais:**
* **[Let's build GPT: from scratch, in code, spelled out.](https://www.youtube.com/watch?v=kCc8FmEb1nY)- Andrej Karpathy (1h)**
* **[Large Language Models explained briefly](https://www.youtube.com/watch?v=LPZh9BOjkQs) - 3blue1brown (10min)**
* **[Neural networks](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi) - 3blue1brown (10min)****
* **[Large Language Models Explained](https://www.youtube.com/watch?v=5sLYAQS9sWQ) - Andrej Karpathy (1h)**
- **[Intro to Large Language Models](https://www.youtube.com/watch?v=zjkBMFhNj_g) - Andrej Karpathy (1h)**
- **[How ChatGPT Works Technically](https://www.youtube.com/watch?v=bSvTVREwSNw) - ByteByteGo(30min)**
- **[sentdex](https://www.youtube.com/user/sentdex)**
- **[Sebastian Raschka](https://www.youtube.com/@SebastianRaschka)**
- **[Jeremy Howard - course.fast.ai](https://www.youtube.com/@howardjeremyp)**
- **[MIT OpenCourseWare](https://www.youtube.com/@mitocw)**
- **[Stanford Online](https://www.youtube.com/@stanfordonline)**
- **[Stanford Online](https://www.youtube.com/@stanfordonline)**


---
## **üõ†Ô∏è Tutoriais Pr√°ticos**

- **[Build a RAG App with Python](https://python.langchain.com/docs/tutorials/rag)**
- **[llama.cpp](https://github.com/ggml-org/llama.cpp)**
- **[Ollama](https://ollama.com/)**
- **[Running Ollama on Docker: A Quick Guide](https://dev.to/gabriellavoura/running-ollama-on-docker-a-quick-guide-475l)**
- **[RAG 101](https://txt.cohere.com/rag-101/ )**
- **[Building RAG from Scratch](https://www.youtube.com/watch?v=BrsocJb-fAo)** - Coding with Lewis (45min)

### **üîß Ferramentas e Plataformas**
* **Desenvolvimento**
	- **[Hugging Face](https://huggingface.co/)** - Hub de modelos e datasets
	- **[LangChain](https://python.langchain.com/)** - Framework para aplica√ß√µes LLM
	- **[LlamaIndex](https://www.llamaindex.ai/)** - Framework para RAG
	- **[chainlit](https://docs.chainlit.io/get-started/overview) - Framework para interfaces**
	- **[Streamlit](https://streamlit.io/) - Framework para interfaces**
	- **[Gradio](https://www.gradio.app/) - Deploy de notebooks como aplica√ß√µes**
	- **[Google Colab](https://colab.google/) - Notebook python com suporte a GPU/TPUs**
	- **[Free LLM APis Resource](https://github.com/cheahjs/free-llm-api-resources)**
* **Bancos Vetoriais**
	- **[Chroma](https://www.trychroma.com/)** - Open-source vector store
	- **[Weaviate](https://weaviate.io/)** - Vector database com GraphQL
	- **[FAISS](https://faiss.ai/)** - Facebook AI Similarity Search
* **Avalia√ß√£o**
	- **[RAGAS](https://docs.ragas.io/)** - Framework de avalia√ß√£o para RAG
	- **[TruLens](https://www.trulens.org/)** - Avalia√ß√£o de aplica√ß√µes LLM

---

## üß™ Desafio T√©cnico: Construa seu Mini Chat-GPT local com conhecimento personalizado

Neste desafio, voc√™ dever√° construir um assistente conversacional local e leve usando modelos pequenos de 3B a 7B par√¢metros como LLaMA 3.x, DeepSeek, Qwen, Mistral ou Gemma, rodando via Ollama ou llama.cpp, utilizando a linguagem de programa√ß√£o python e o framework langchain.
A aplica√ß√£o deve ser baseada na t√©cnica de RAG (Retrieval-Augmented Generation), onde o LLM responde perguntas a partir de documentos fornecidos por voc√™.

Ao concluir este desafio voc√™ aprender√° a:
* Usar um modelo local (ollama/llama.cpp com deepseek-r1, ou llama3.2/3.1, Qwen3)
* Manipular o framework langchain.
* Montar um sistema de busca sem√¢ntica de documentos (ChromaDB)
* Desenvolver um frontend de chat (com Chainlit/streamlit)
* Conceitos gerais de LLMs e RAG.

### Dicas:
* Utilize `prompt templates` para personalizar as intera√ß√µes e dividir atividades complexas.
* Armazenar as respostas (caching)  para evitar reprocessar informa√ß√µes [redis](https://redis.io/).

### Follow-up: 

Ap√≥s concluir o desafio principal, implemente algumas das aplica√ß√µes abaixo.

| Tarefa                | Objetivo                                                                          |
| --------------------- | --------------------------------------------------------------------------------- |
| üìë Sumariza√ß√£o        | Gerar resumo autom√°tico de PDF ou artigos cient√≠ficos                             |
| üìÑ Extra√ß√£o de dados  | Pegar datas, nomes, c√≥digos de um documento estruturado                           |
| ‚úÖ Classifica√ß√£o       | Separar textos entre positivos/negativos (sentimento, tema)                       |
| ü§ñ Assistente offline | Criar um bot de ajuda local para um dom√≠nio espec√≠fico                            |
| üß† Fine-tuning leve   | Usar QLoRA com dados pr√≥prios para melhorar respostas                             |
| üìö RAG Multifonte     | Buscar respostas em v√°rios conjuntos (artigos + manuais)                          |
| üîç Busca sem√¢ntica    | Procurar termos "similares" sem depender de palavras-chave (dist√¢ncias vetoriais) |

> **Keywords**: RAG, LLM, Prompt Template, langchain, vectorial database, chromadb, python
